{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>The graph initialisation</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"<h1>The graph initialisation</h1>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = {\"cluster1-cntx\":[\"cluster1-cntx\",\"cluster3-cntx\"], \"cluster2-cntx\":[\"cluster2-cntx\",\"cluster3-cntx\"], \"cluster3-cntx\":[\"cluster3-cntx\",\"cluster1-cntx\",\"cluster2-cntx\"]}\n",
    "link_latency = {\"cluster1-cntx\":{\"cluster1-cntx\":1, \"cluster3-cntx\":10},\"cluster2-cntx\":{\"cluster2-cntx\":1, \"cluster3-cntx\":20}, \"cluster3-cntx\":{\"cluster3-cntx\":1, \"cluster1-cntx\":10,\"cluster2-cntx\":20}}\n",
    "                                 \n",
    "bf = {\"firewall\":{\"firewalls\":10, \"firewallm\":5, \"firewalll\":1}, \"encrypt\":{\"encrypts\":10, \"encryptm\":5, \"encryptl\":1}, \"decrypt\":{\"decrypts\":10, \"decryptm\":5, \"decryptl\":1}}\n",
    "G_req = {\"firewall\":[\"encrypt\"], \"encrypt\":[\"firewall\"]}#, \"decrypt\":[\"firewall\"]}\n",
    "usecase = {1:{\"firewall\":300,\"encrypt\": 300, \"decrypt\":300, \"SLA\":10}, 2:{\"firewall\":100,\"encrypt\": 100}, \"SLA\": 100}\n",
    "u =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>The graph illustration</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"<h1>The graph illustration</h1>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "\n",
    "def draw(G):\n",
    "    infra = nx.DiGraph()\n",
    " #   for cl in range(len(G)):\n",
    " #       i = list(G.keys())[cl]\n",
    " #       infra.add_node(i)\n",
    "    for cl in range(len(G)):\n",
    "        i = list(G.keys())[cl]\n",
    "        for link in range(len(G[i])):\n",
    "            infra.add_edges_from([(i, G[i][link])], weight=link_latency[i][G[i][link]])\n",
    "    edge_labels=dict([((u,v,),d['weight'])\n",
    "                 for u,v,d in infra.edges(data=True)])\n",
    "\n",
    "\n",
    "    pos = nx.spring_layout(infra)\n",
    "    nx.draw_networkx_edge_labels(infra,pos,edge_labels=edge_labels)\n",
    "    nx.draw_networkx_labels(infra, pos)\n",
    "    #plt.figure(figsize=(8,8))\n",
    "    \n",
    "    nx.draw(infra, pos=pos, with_labels=True)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The number of running pods of a microservice on each cluster\n",
    "import os\n",
    "def runningPods(cluster, app_name):\n",
    "    output = os.popen('sudo kubectl top pod --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    numPods = 0\n",
    "    which_app = len(app_name)\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if len(items[0]) > 8 and items[0][:which_app] == app_name:\n",
    "            numPods += 1\n",
    "    return numPods\n",
    "runningPods(\"cluster1-cntx\",\"firewall\"+'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The utilised CPU of a microservice running on a cluster\n",
    "import os\n",
    "def getchar(string, n):\n",
    "    return str(string)[n - 1]\n",
    "def cpuUtilised(cluster, app_name):\n",
    "    output = os.popen('kubectl top pod --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    which_app = len(app_name)\n",
    "    cpu = ''\n",
    "    cpu_u=0\n",
    "    limits=0\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if items[0][:which_app] == app_name:\n",
    "            if getchar(items[0], which_app) == 's':\n",
    "                cpu = items[1]\n",
    "                cpu = cpu[:-1]\n",
    "                cpu = int(cpu)\n",
    "                cpu_u=cpu_u + cpu\n",
    "            if getchar(items[0], which_app) == 'm':\n",
    "                cpu = items[1]\n",
    "                cpu = cpu[:-1]\n",
    "                cpu = int(cpu)\n",
    "                cpu_u=cpu_u + cpu\n",
    "            if getchar(items[0], which_app) == 'l':\n",
    "                cpu = items[1]\n",
    "                cpu = cpu[:-1]\n",
    "                cpu = int(cpu)\n",
    "                cpu_u=cpu_u + cpu\n",
    "\n",
    "        \n",
    "                \n",
    "#    print(limits - cpu_u)\n",
    "    return cpu_u\n",
    "\n",
    "\n",
    "cpuUtilised(\"cluster1-cntx\",\"firewall\"+'m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The available CPU of a microservice running on a cluster\n",
    "import os\n",
    "def getchar(string, n):\n",
    "    return str(string)[n - 1]\n",
    "def cpuAvail(cluster, app_name):\n",
    "    output = os.popen('kubectl top pod --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    which_app = len(app_name)\n",
    "    cpu = ''\n",
    "    cpu_u=0\n",
    "    limits=0\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if items[0][:which_app] == app_name:\n",
    "            if getchar(items[0], which_app) == 's':\n",
    "                limits = 600\n",
    "                cpu = items[1]\n",
    "                cpu = cpu[:-1]\n",
    "                cpu = int(cpu)\n",
    "                cpu_u=cpu_u + cpu\n",
    "            if getchar(items[0], which_app) == 'm':\n",
    "                limits = 5*600\n",
    "                cpu = items[1]\n",
    "                cpu = cpu[:-1]\n",
    "                cpu = int(cpu)\n",
    "                cpu_u=cpu_u + cpu\n",
    "            if getchar(items[0], which_app) == 'l':\n",
    "                limits = 10*600\n",
    "                cpu = items[1]\n",
    "                cpu = cpu[:-1]\n",
    "                cpu = int(cpu)\n",
    "                cpu_u=cpu_u + cpu\n",
    "\n",
    "        \n",
    "                \n",
    "#    print(limits - cpu_u)\n",
    "    return limits - cpu_u\n",
    "\n",
    "\n",
    "cpuAvail(\"cluster1-cntx\",\"firewall\"+'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Which microservice configuration is running: small, medium, or large\n",
    "def getchar(string, n):\n",
    "    return str(string)[n - 1]\n",
    "def whichConf(cluster, app_name):\n",
    "    size = []\n",
    "    output = os.popen('sudo kubectl get services --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    which_app = len(app_name)\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if items[0][:which_app] == app_name:\n",
    "            size.append(getchar(items[0], which_app+1))\n",
    "    #        print(size)\n",
    "    return size\n",
    "whichConf(\"cluster1-cntx\",\"firewall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This function orders the running microservies on a cluster increasingly according to proccessing delay\n",
    "def orderService(cluster, app_name):\n",
    "    delay = []\n",
    "    size = whichConf(cluster, app_name)\n",
    "    for s in range(len(size)):\n",
    "        delay.append(bf[app_name][app_name+size[s]])\n",
    "    sorted_delay = [x for _,x in sorted(zip(delay,size))]\n",
    "    return sorted_delay\n",
    " #   print(delay)\n",
    "                \n",
    "    \n",
    "orderService(\"cluster1-cntx\",\"firewall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "def getIP(cluster, app_name):\n",
    "    output = os.popen('kubectl get service -o wide --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    serviceIP = ''\n",
    "    port=''\n",
    "    which_app = len(app_name)\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if items[0][:which_app] == app_name:\n",
    "            serviceIP=items[2]+\":\"+items[4][:4]\n",
    "    return serviceIP\n",
    "getIP(\"cluster1-cntx\",\"firewall\"+'m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cluster1-cntx', 'cluster3-cntx']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This function orders the available links from source cluster increasingly according to latency\n",
    "def orderlink(cluster):\n",
    "    delay = []\n",
    "    cnx = []\n",
    "    for key in range(len(list(link_latency[\"cluster1-cntx\"].keys()))):\n",
    "        delay.append(link_latency[\"cluster1-cntx\"][list(link_latency[\"cluster1-cntx\"].keys())[key]])\n",
    "        cnx.append(list(link_latency[\"cluster1-cntx\"].keys())[key])\n",
    "    sorted_delay = [x for _,x in sorted(zip(delay,cnx))]\n",
    "    return sorted_delay\n",
    " #   print(delay)\n",
    "                \n",
    "    \n",
    "orderlink(\"cluster1-cntx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-149"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Available CPU on a cluster in millicores\n",
    "def clusterCPU(cluster):\n",
    "    cpu=0\n",
    "    cpu_cl=0\n",
    "    output = os.popen('sudo kubectl top nodes --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if items[0] != \"NAME\":\n",
    "            cpu = items[1]\n",
    "            cpu = cpu[:-1]\n",
    "            cpu = int(cpu)\n",
    "            cpu_cl = cpu_cl + cpu\n",
    "    #        print(size)\n",
    "    return 2000 - cpu_cl\n",
    "\n",
    "clusterCPU('cluster1-cntx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Place and Assign new mircroservice to requests</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"<h1>Place and Assign new mircroservice to requests</h1>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cluster1-cntx', 'cluster2-cntx']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Returns the lists of clusters on which a microservice type is running\n",
    "def checkdeploy(app_name):\n",
    "    cl = 0\n",
    "    p=0\n",
    "    cluster=[]\n",
    "    while p == 0:\n",
    "        for cl in range(len(G)):\n",
    "            i = list(G.keys())[cl]\n",
    "            output = os.popen('sudo kubectl get services --context=' +i).read()\n",
    "            lines = output.split(\"\\n\")\n",
    "            which_app = len(app_name)\n",
    "            for line in lines[:-1]:\n",
    "                items = line.split()\n",
    "                if items[0][:which_app] == app_name:\n",
    "                    cluster.append(i)\n",
    "                    p=1\n",
    "                    \n",
    "    return cluster\n",
    "checkdeploy(\"proxy\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignService(i, q, usecase_s):\n",
    "#    req = 1\n",
    "#    cl = 1\n",
    "    config_idx='' \n",
    "    size=[]\n",
    "    avail=0\n",
    "    cpu_q= usecase_s[u][q]\n",
    "    r = runningPods(i, q)\n",
    "    if r >= 1: #there's a function already running on this cluster \n",
    "        size = orderService(i,q) #which function size is running? order by delay\n",
    "        for s in range(len(size)): \n",
    "            avail = cpuAvail(i, q+size[s]) #the available CPU depends on the service configuration\n",
    "            if avail > cpu_q: #if the available resources > profiled resources requested \n",
    "                config_idx = size[s] #then get IP to assign the service to proxy\n",
    "                break\n",
    "    elif r ==0 : #no service running \n",
    "        config_idx=''          \n",
    "    #print(proxy_conf)\n",
    "    return config_idx\n",
    "\n",
    "def newService(i,q, usecase_s):\n",
    "    config_idx=''\n",
    "    cpu_q= usecase_s[u][q]\n",
    "    r = runningPods(i, q)\n",
    "    if 600 > cpu_q and runningPods(i, q+'s') == 0 and 600 < clusterCPU(i): #deploy new small service\n",
    "        #place(i,q,'s')\n",
    "        config_idx='s'       \n",
    "    elif 5*600 > cpu_q and runningPods(i, q+'m')==0 and 5*600 < clusterCPU(i): #deploy new medium service\n",
    "        config_idx='m'\n",
    "    elif 10*600 > cpu_q and runningPods(i, q+'l')==0 and 10*600 < clusterCPU(i): #deploy new large service\n",
    "        config_idx='l'\n",
    "\n",
    "  #  elif proxy_conf=='':\n",
    "  #      print(\"placement failed\")\n",
    "        \n",
    "    \n",
    "    #print(proxy_conf)\n",
    "    return config_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Monitor and delete function</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"<h1>Monitor and delete function</h1>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread is starting\n",
      "[['cluster2-cntx', 0, 's', 'firewall', 0]]\n",
      "thread is starting\n",
      "[['cluster2-cntx', 0, 's', 'encrypt', 0]]\n"
     ]
    }
   ],
   "source": [
    "#def monitorUsage(t): #This function is terminate services once idle for a time \n",
    "import threading\n",
    "import time\n",
    "import os\n",
    "\n",
    "def deletePod(app_name, timer, cluster):\n",
    "    print(\"thread is starting\")\n",
    "    action=[None] * 5\n",
    "    policy=[]\n",
    "    cpu = 0\n",
    "    timeout = time.time() + timer\n",
    "    while cpu == 0:\n",
    "        cpu= cpuUtilised(cluster, app_name)\n",
    "        if time.time() > timeout:\n",
    "            action[0]=cluster\n",
    "            action[1]=0\n",
    "            action[2]= app_name[len(app_name)-1]\n",
    "            action[3]= app_name[:-1]\n",
    "            action[4]= 0\n",
    "            policy.append(action)\n",
    "            break\n",
    "    return policy\n",
    "class ThreadWithResult(threading.Thread):\n",
    "    def __init__(self, group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None):\n",
    "        def function():\n",
    "            self.result = target(*args, **kwargs)\n",
    "        super().__init__(group=group, target=function, name=name, daemon=daemon)\n",
    "\n",
    "        \n",
    "def monitorUsage(cluster, timer):\n",
    "\n",
    "    for service in range(len(bf)):\n",
    "        threads = list()\n",
    "        ser = list(bf.keys())[service]\n",
    "        s = whichConf(cluster,ser)\n",
    "        if s != []:\n",
    "            for size in range(len(s)):\n",
    "                app_name=ser+s[size]\n",
    "                x =ThreadWithResult(target=deletePod, args=(app_name, timer, cluster,))\n",
    "                x.daemon = True\n",
    "                threads.append(x)\n",
    "                x.start()\n",
    "            for x in threads:\n",
    "                x.join()\n",
    "                print(x.result)\n",
    "                \n",
    "\n",
    "        \n",
    "monitorUsage(\"cluster2-cntx\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cluster2-cntx', 2, 's', 'encrypt', 'proxy'],\n",
       " ['cluster2-cntx', 2, 's', 'encrypt', 'proxy']]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this feeds the RL agent with heuristic policies \n",
    "#[cluster-idx, action-idx, config-idx, app-idx, proxy-idx]\n",
    "\n",
    "def main(proxy, G_req):\n",
    "\n",
    "    proxy_idx=proxy\n",
    "    action=[None] * 5\n",
    "    policy=[]\n",
    "    m_cl= ''\n",
    "    m_ser=[]\n",
    "\n",
    "    startingCluster = checkdeploy(proxy_idx)\n",
    "    OG = orderlink(startingCluster) #try the fastest link first\n",
    "    for cl in range(len(OG)): #go over clusters \n",
    "        i = list(G.keys())[cl]\n",
    "        for req in range(len(G_req)):\n",
    "            q = list(G_req.keys())[req] #go over functions to deploy\n",
    "            if req == 0 and q not in m_ser: #The first function can be deployed on any cluster\n",
    "                if assignService(i,q, usecase) != \"\": #there is atleast one good candidate service running on i \n",
    "                    action[0]=i\n",
    "                    action[1]=1\n",
    "                    action[2]= assignService(i,q, usecase)\n",
    "                    action[3]= q\n",
    "                    action[4]= proxy_idx\n",
    "                    policy.append(action)\n",
    "                    m_cl= i #to check connection with next deployment\n",
    "                    m_ser.append(q)\n",
    "                    \n",
    "                    continue                \n",
    "            elif m_cl in G[i] and q not in m_ser: #connection with previous bf and not already deployed\n",
    "                if assignService(i,q, usecase) != \"\": #can be deployed\n",
    "                    action[0]=i\n",
    "                    action[1]=1\n",
    "                    action[2]= assignService(i,q, usecase)\n",
    "                    action[3]= q\n",
    "                    action[4]= proxy_idx\n",
    "                    policy.append(action)\n",
    "                    m_cl= i\n",
    "                    m_ser.append(q)\n",
    "                    continue\n",
    "        if len(m_ser) < len(G_req): #not all deployed yet we try a different cluster      \n",
    "            continue \n",
    "        else:\n",
    "            break\n",
    "    if len(m_ser) < len(G_req): #not all functions could be deployed \n",
    "        for cl in range(len(OG)): #go over clusters \n",
    "            i = list(G.keys())[cl]\n",
    "            for req in range(len(G_req)):\n",
    "                q = list(G_req.keys())[req] #go over functions to deploy\n",
    "                if req == 0 and q not in m_ser:\n",
    "                    if newService(i,q, usecase) != '':\n",
    "                        action[0]=i\n",
    "                        action[1]=2\n",
    "                        action[2]= newService(i,q, usecase)\n",
    "                        action[3]= q\n",
    "                        action[4]= proxy_idx\n",
    "                        policy.append(action)\n",
    "                        m_cl= i\n",
    "                        m_ser.append(q)\n",
    "                        continue\n",
    "                elif m_cl in G[i] and q not in m_ser: #connection with previous bf and not already deployed\n",
    "                        if newService(i,q, usecase) != '':\n",
    "                            action[0]=i\n",
    "                            action[1]=2\n",
    "                            action[2]= newService(i,q, usecase)\n",
    "                            action[3]= q\n",
    "                            action[4]= proxy_idx\n",
    "                            policy.append(action)\n",
    "                            m_cl= i\n",
    "                            m_ser.append(q)\n",
    "                            continue  \n",
    "    #proxyConfig(IPs, proxy)\n",
    "    #print(IPs)\n",
    "    #print(m_ser)\n",
    "    return policy\n",
    "    \n",
    "main(\"proxy\", G_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Deploy and monitor microservices</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"<h1>Deploy and monitor microservices</h1>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread is starting\n",
      "[['cluster2-cntx', 0, 's', 'firewall', 0]]\n",
      "thread is starting\n",
      "[['cluster2-cntx', 0, 's', 'encrypt', 0]]\n",
      "[['cluster2-cntx', 2, 's', 'encrypt', 'proxy'], ['cluster2-cntx', 2, 's', 'encrypt', 'proxy']]\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "threads = list()\n",
    "x =ThreadWithResult(target=main, args=(proxy, G_req,))\n",
    "x.daemon = True\n",
    "x.start()\n",
    "threads.append(x)\n",
    "for cl in range(len(G)): #go over clusters \n",
    "        i = list(G.keys())[cl]\n",
    "        x = ThreadWithResult(target=monitorUsage, args=(i,10, ))\n",
    "        x.daemon = True\n",
    "        threads.append(x)\n",
    "        x.start()\n",
    "for x in threads:\n",
    "    x.join()\n",
    "    print(x.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
