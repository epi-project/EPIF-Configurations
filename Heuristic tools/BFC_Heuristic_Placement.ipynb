{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>The graph initialisation</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"<h1>The graph initialisation</h1>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = {\"cluster1-cntx\":[\"cluster1-cntx\",\"cluster3-cntx\"], \"cluster2-cntx\":[\"cluster2-cntx\",\"cluster3-cntx\"], \"cluster3-cntx\":[\"cluster3-cntx\",\"cluster1-cntx\",\"cluster2-cntx\"]}\n",
    "link_latency = {\"cluster1-cntx\":{\"cluster1-cntx\":1, \"cluster3-cntx\":10},\"cluster2-cntx\":{\"cluster2-cntx\":1, \"cluster3-cntx\":20}, \"cluster3-cntx\":{\"cluster3-cntx\":1, \"cluster1-cntx\":10,\"cluster2-cntx\":20}}\n",
    "                                 \n",
    "bf = {\"firewall\":{\"firewalls\":10, \"firewallm\":5, \"firewalll\":1}, \"encrypt\":{\"encrypts\":10, \"encryptm\":5, \"encryptl\":1}, \"decrypt\":{\"decrypts\":10, \"decryptm\":5, \"decryptl\":1}}\n",
    "G_req = {\"firewall\":[\"encrypt\"], \"encrypt\":[\"firewall\"]}#, \"decrypt\":[\"firewall\"]}\n",
    "usecase = {1:{\"firewall\":300,\"encrypt\": 300, \"decrypt\":300, \"SLA\":10}, 2:{\"firewall\":100,\"encrypt\": 100}, \"SLA\": 100}\n",
    "u =1\n",
    "#G = {\"cluster1-cntx\":[\"cluster1-cntx\", \"cluster2-cntx\"], \"cluster2-cntx\":[\"cluster2-cntx\", \"cluster1-cntx\"]}\n",
    "#link_latency = {\"cluster1-cntx\":{\"cluster1-cntx\":1, \"cluster2-cntx\":100}, \"cluster2-cntx\":{\"cluster2-cntx\":1, \"cluster1-cntx\":100}, \"cluster3-cntx\":{\"cluster2-cntx\":10, \"cluster1-cntx\":10}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cluster1-cntx', 'cluster3-cntx']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G[\"cluster1-cntx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>The graph illustration</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"<h1>The graph illustration</h1>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlzElEQVR4nO3deVRV9f7/8efeHOCADKcOKKk4pQYOOCClgaVpOeTV682cQ1HK1BzTorx5wyEzb/7ya0mYd2mWOZZ2RbTEr1YOWZam3iSzEkUFGUJAOQyez/ePfp0bJYoGZzO8H2u5Fpz92ZvXPtXLTx/23kdTSimEEEI4hW50ACGEqE2kdIUQwomkdIUQwomkdIUQwomkdIUQwomkdIUQwomkdIUQwomkdIUQwomkdIUQwomkdIUQwomkdIUQwomkdIUQwomkdIUQwomkdIUQwomkdIUQwolMRgcAyMwvZNNXqSSn5ZJrK8HHbCIowIdHQxti9XI3Op4QQlQYzciHmH9zNoc39pzik5MZABSW2B3bzCYdBXS7y58J9zenXaDFmJBCCFGBDCvddz8/zfzEZGwlV7leAk0Ds8mFWX2DGNm5idPyCSFEZTBkeeGXwj1BQbH9hmOVgoLiq8xPPAEgxSuEqNac/ou0b87mMD8xuVyF+1sFxXbmJyZzNDWncoIJIYQTVErpaprGrl27rrntjT2nsJVcveExLm5ewJl/PkLKy/049+bjANhKrrJsz6kKzWqxWBg1alSFHlMIIcri1JluZn4hn5zMuO4arr2kCABX33p4d/oLJr9AxzalYPd3GWTlF1Z2VCGEqBTXLV1N07DZbI7vfzsr3LVrFxaLBU3T0HWdRo0aAeDr6wtAz5490TSNKVOmADB79mzqW305Oa8vZxY/yuXkvY7jpizsT/qGf5CyaCBn//k37CVF3PbAGG7rNhrd7F06E7Dp69Q/ZD148CD169dH13V0XSckJASA6OhofHx86NSpE7qu4+rqypw5cwAIDw/n0qVLrF69Gk3TCAkJIT4+Hl3XOXjwIAAbNmxA13USExPL/64KIUQZbnmmO2bMGMLCwiguLiY7O5uYmBgALl26BEBSUhJKKZYsWcLatWuZN28e949+lsAZH+AZ3JXMD1/BbrviOJ7tzDHqDV9Ag8nvoZvcyvy5thI7yRfySr1WVFREt27dCAgIIC0tjezsbJ588knH9ry8PFq1aoXNZmPQoEHExsZit9vZt28fvr6+REZGopTi6NGjjBs3ji5dutC7d2+ys7OJjIzkkUceoW/fvrf6VgkhhMMtl67JZCI1NZXDhw9jsViYMGFCmWPnzZtHeHg4gff2Qze54ddnMmg6+cd2OsbUCeqKuUEQJk+fG/7sXFtxqe9XrVpFYWEh+/fvp27dun/IYzKZWL16NW5ubixduhS73c7x48fLPP7OnTspLCykfv36eHl5sX79+htmEkKI8rjl0t28eTNKKTp37ozZbCYqKqrMsRkZGezdu5eVo+8m5eV+pLzcD+wllPx8wTHG1dqw3D/7vUkPoWkamqYxYcIETpw4gYeHB2az+ZrjPTw8HF/7+fk5MpXF09OTvn37UlhYyIwZM9B1uVtaCFExbtgmmZmZjq8LCgocX4eEhJCcnMzVq1dZvHgxq1atKvOKBavVSs+ePYnbc4qWf0+kcUwCjWMSuP2h/y4BoGnlCmw26byWcAilFEopli1bRnBwMAUFBaXWn8tLu8bPPXToEB988AEtWrQgNjaW3Nzcmz6uEEJcy3VLV9d1ZsyYQVFREVFRURQVFTm2TZ8+nS+//BKABg0aAODi4uLY74svvnCMfe6559i9ezeF/0nCbrdTcjmHnz9bQ0leVpk/215ShN2WD/arKGXHbsvHXlKEAgZ1LD0rHj16NO7u7kRERHDx4kVycnKIi4sr1xvg7e3N999//9+fa7fTq1cvwsLCSE5Opk6dOvTs2bNcxxJCiBtS1xEbG6tMJpMCVGhoqPL19VWRkZFKKaXCwsKUrusKUCaTSY0YMcKx37Bhwxzbpk6dqpRSau7cucrT01MBCk1TLl5W1WDi26pxTIJC05Wl22jVOCbB8cc9sM0vY3/zxz2wjRr11t5rZt2/f78KCAhQmqYpTdNUSEiIUkqpsWPHKm9v71JjAZWUlKSUUio+Pl65uro69hk4cKAym80qLy9PKaXUV199pTRNU0uXLr3eWyWEEOXi9GcvfHM2h6FvfU5B8Y1vkPg9F66SuuppXPMu0Lp1a5o1a0bLli0ZN24c9evXr4S0QghRsQx54M3NPHvhVx6uOrP6BrMiZjSffPKJ43VN0/j6669p3759JSQVQoiKVe2eMvbzzz/TqFEj8vPzAbjzzjtJTk7GZKoSjwYWQojrMuxaqJGdm7D+ic70alUPd5OO2VQ6itmk427S6dWqHuuf6Ox4uthtt93GokWLcHNzw2KxkJ6ejtVqZceOHQachRBC3BxDH2L+q6z8QjZ9nUryhTxybcX4mF0JusObQR2v/ckRV69epU+fPjz33HNEREQwbNgwPvjgA3r16sXmzZvLvF5XCCGMViVKtyLs3buXAQMGUFBQwMqVKxkyZIjRkYQQ4g9qzK1WERERZGRkMHz4cIYNG0Z4eDg5OTlGxxJCiFJqTOnCLzdlrFixgsOHD3P69Gnq1avHm2++aXQsIYRwqFGl+6t27dpx7tw5Jk+ezMSJE2nXrh1paWlGxxJCiJpZur9atGgRJ0+e5PLlyzRs2JAFCxYYHUkIUcvVmF+k3chLL73E7Nmzadq0KR999BHNmjUzOpIQohaq0TPd33r++ec5e/Ysnp6etGjRgpkzZxodSQhRC9Wame5vLVu2jGnTpuHv709iYqLjo32EEKKy1ZqZ7m9NmDCB9PR0GjduTPv27YmOjsZuv7mPhBdCiFtRK2e6v7V+/XqioqLw9PRky5YtREREGB1JCFGD1cqZ7m8NGTKErKwswsLCuO+++xg0aBAlJSVGxxJC1FC1vnThl89Q2759O9u2bWPnzp3cfvvtbNu2zehYQogaSEr3N/r06UNWVhZ9+vThL3/5Cw899BBXrly58Y5CCFFOUrq/YzKZWL9+PZ999hmHDx/GarWyZs0ao2MJIWoIKd0yhIeHk56eTmRkJI899hhdunQhOzvb6FhCiGpOSvc6dF0nPj6eo0ePkpqaSkBAAG+88YbRsYQQ1ZiUbjm0adOGs2fPMm3aNCZPnkzbtm05f/680bGEENWQlO5NWLhwIadOnaKoqIhGjRoxd+5coyMJIaqZWn9zxK165ZVXmDVrFo0aNWLHjh20aNHC6EhCiGpAZrq36JlnniE1NRUfHx+CgoKYNm2a3EoshLghmelWgOXLlzNp0iSsVivbtm2jQ4cORkcSQlRRMtOtAE888QQZGRk0b96c0NBQoqKiZNYrhLgmKd0K4uPjw6effsr69evZsGED/v7+fPLJJ0bHEkJUMVK6FezRRx8lKyuLzp070717dwYOHEhRUZHRsYQQVYSUbiUwm81s27aNHTt2sHv3bqxWK//+97+NjiWEqAKkdCvRQw89RGZmJn/5y1/461//So8ePcjPzzc6lhDCQFK6lcxkMvHee+9x4MABjh07hr+/P2+//bbRsYQQBpHSdZJ77rmHtLQ0oqKiiIqK4u677yYrK8voWEIIJ5PSdSJd11m2bBnHjh0jPT2dO+64gyVLlhgdSwjhRFK6BmjdujUpKSnMnDmTp59+mtatW3P27FmjYwkhnEBK10Dz58/nhx9+wG6307RpU1588UWjIwkhKpncBlxFvPrqq8TExNCwYUO2b99OUFCQ0ZGEEJVAZrpVxNNPP8358+exWq20bt2aKVOmyK3EQtRAMtOtgv71r38xceJELBYLCQkJdOrUyehIQogKIjPdKmjs2LFkZGQQFBTE3XffzWOPPca1/m6Uvy+FqH6kdKsob29v9uzZw8aNGzlz5sw1xxw+fJiePXsSHx/v5HRCiFslywvVgN1uR9M0NE0r9fqxY8c4cOAAkydP5tChQ7Rp08aghEKI8pKZbjWg6/ofChegbdu2eHt7061bN9q0aYNSisuXL7Nq1Sq57leIKkpKtxorKCggPj6eMWPGALBx40ZmzpzJli1b6NGjB//85z8NTiiE+D0p3Wpsx44dFBYWMnjwYABeeOEFHnzwQbZs2UJ8fDwXL14E5BduQlQlUrrV2MqVKxkyZAgA//M//8Ntt93GwIEDAWjUqBHffPMNOTk511yaEEIYw2R0AHFzcnNziY+Pp2XLlmRmZjJ16lQA4uLiWLRokWPcunXrcHd3x2KxoJSS4hWiipDSrYZ+/PFH5s6di5eXF3a7nW+//ZZ69erRu3dv7HY7uq4TFxfHunXrjI4qhPgdWV6oZnx8fIiLi+PcuXOMGjWK+fPn4+7uTsuWLcnPz0fXdd544w0aN25MRESEzHKFqGLkOt0awG63M3ToUNLS0mjZsiV2u52xY8cSHh7umPkKIaoGKd0a5MMPP+TMmTOMHj0ab2/vUtuUUiilpICFMJiUbg3122UFpRQ7d+5k5MiRbN26lXvuucfgdELUXjLtqaF+u46raRr33nsvbdu2pUuXLgwfPpySkhID0wlRe0np1hJeXl7s2rWLLVu2sHXrVvz8/Ni5c6fRsYSodaR0a5n+/fuTlZVF9+7d6dWrFw8//DA2m83oWELUGlK6tZCbmxubN2/mf//3fzlw4ABWq5WNGzcaHUuIWkFKtxbr1q0bmZmZDB48mCFDhtC1a1dyc3ONjiVEjSalW8vpus7KlSs5dOgQp06dwt/fn7feesvoWELUWFK6AoCOHTty7tw5Jk6cyJNPPkmHDh1IT083OpYQNY6UrnDQdZ3FixeTnJxMbm4uDRs2ZOHChUbHEqJGkZsjRJnmzJnDnDlzaNasGR9//DFNmjQxOpIQ1Z7MdEWZZs+eTUpKCu7u7tx5553ExMQYHUmIak9muqJcli5dytNPP029evXYvn27fAimELdIZrqiXCZNmkRaWhoNGzYkJCSEJ554ArvdbnQsIaodKV1RbrfffjsHDhxg9erVvPPOO9SrV4/9+/cbHUuIakVKV9y0kSNHkpWVRYcOHYiIiGDw4MHyAB0hyklKV9wST09PPv74Y7Zu3cqOHTuwWq1s377d6FhCVHlSuuJPefjhh8nKyuLBBx/k4Ycfpnfv3ly5csXoWEJUWVK64k9zdXVl06ZNfPrpp3z55Zf4+fmxdu1ao2MJUSVJ6YoKExERQUZGBsOHD2fEiBGEh4eTk5NjdCwhqhQpXVGhdF1nxYoVHDlyhNOnT1OvXj3i4uKMjiVElSGlKypFSEgI586dY/LkyTz11FO0a9eOCxcuGB1LCMNJ6YpKtWjRIk6ePMnly5cJDAxk/vz5RkcSwlByG7BwmpdeeonZs2fTpEkTPvroI+68806jIwnhdDLTFU7z/PPPk5qaSp06dWjZsiUzZ840OpIQTiczXWGIuLg4pk6dip+fH9u2baN9+/ZGRxLCKWSmKwwxfvx40tPTadKkCR07diQ6OloeoCNqBZnpCsOtX7+eqKgoPDw8+PDDD4mIiDA6khCVRma6wnBDhgwhMzOTu+++m/vuu49HHnmEoqIio2MJUSmkdEWV4Onpyfbt29m2bRtJSUn4+fmRkJBgdCwhKpyUrqhS+vTpQ1ZWFn379qV///48+OCD8gAdUaNI6Yoqx2QysW7dOj777DOOHDmC1WplzZo1RscSokJI6YoqKzw8nPT0dEaNGsVjjz1G586dyc7ONjqWEH+KlK6o0nRd58033+To0aOcO3eOgIAAli5danQsIW6ZlK6oFtq0acPZs2eZNm0aU6dOpW3btqSmphodS4ibJqUrqpWFCxdy6tQpioqKaNKkCXPmzDE6khA3RUpXVDtNmzblu+++46WXXmLu3Lk0a9aMkydPOrbn5+cj9/yIqkpKV1RbzzzzDOfOncNisRAcHMy0adPIycnhzjvvZMmSJUbHE+Ka5DZgUSMsX76cSZMm4eLiQnFxMe7u7vz000/4+/v/YWxmfiGbvkolOS2XXFsJPmYTQQE+PBraEKuXuwHpRW0ipStqjISEBPr3749SCk3TGDZsWKnre785m8Mbe07xyckMAApL/vuAHbNJRwHd7vJnwv3NaRdocXJ6UVtI6YoaIyQkhJMnT3L16lVKSkoAWLFiBWPHjuXdz08zPzEZW8lVrvdvvKaB2eTCrL5BjOzcxDnBRa0ipSsMEx0dzYYNG8jNza2Q4/34448cP36cs2fP8v3337Nu3Try8vKYt+4Tln+ZQUFx+R8d6eGqM6tvsBSvqHAmowMI8WdpmkZSUhI9evSgWbNmjtdfe+01PjqUzJR//4TtBoWbGjeGq7kZoBToLni2up/5zCSkoYWQhpYKy2qxWBgwYABvv/12hR1TVC9SuqJGe/9Efqm129+zlxShm9y4rcfjeDRqh2725MoPX5KxaQ6ZTTqwbI8fb47s5MTEoqaTS8aEUxw8eJD69euj6zq6rhMSElJq+969e9E0DZvN5njNYrEwatQoAHbt2oXFYkHTNHRdp1GjRgD4+voC0LNnTzRNY8qUKQDMnj0bDw8P3ooMI+XVR7mcvNdx3JSF/Unf8A9SFg3k7D//hr2kiDotu6CbPQHQ0AAoTPue3d9lkJVfWO7ziY6OxsfHh06dOqHrOq6uro4bOMLDw7l06RKrV69G0zRCQkKIj49H13UOHjwIwIYNG9B1ncTExD/5jouqSkpXVLqioiK6detGQEAAaWlpZGdn8+STT97UMcaMGUNYWBjFxcVkZ2cTExMDwKVLlwBISkpCKcWSJUtYu3Yt8+bNY9Ck2TSP2YJncFcyP3wFu+2/j4i0nTlGveELaDD5PXSTGwDnVkwg5eV+XNz4IpqLKz6dB6EBm74ufbvxjc4nLy+PVq1aYbPZGDRoELGxsdjtdvbt24evry+RkZEopTh69Cjjxo2jS5cu9O7dm+zsbCIjI3nkkUfo27fvrbzVohqQ0hWVbtWqVRQWFrJ//37q1q2LxWJhwoQJN3UMk8lEamoqhw8fvuH+8+bNIzw8HGtob4ox4ddnMmg6+cd2OsbUCeqKuUEQJk8fx2sNopcROOMDbnvwSdwaBKO7eWIrsZN8Ie+mzsdkMrF69Wrc3NxYunQpdrud48ePl5l3586dFBYWUr9+fby8vFi/fv1NvTeiepHSFZXuxIkTeHh4YDabb/kYmzdvRilF586dMZvNREVFlTk2IyODvXv3smRoR1Je7kfKy/3AXkLJzxccY1ytDa+5r25ywye0H1fzs8lMWAxAXHR3NE1D0zQmTJhww/Px8PBwfO3n5+fIVBZPT0/69u1LYWEhM2bMQNflP8uaTP7pikoXHBxMQUFBqfXa37NarQBkZmY6XisoKHB8HRISQnJyMlevXmXx4sWsWrWKXbt2lXmsnj17MmXd1zSOSXD8uf2h3yxpaNr1Q9vtlOT8UtLjV+xGKYVSimXLlpXrfMqiXePnHjp0iA8++IAWLVoQGxtbYZfQiapJSldUutGjR+Pu7k5ERAQXL14kJyeHuLi4UmOCg4PRdZ0ZM2ZQVFREVFRUqQ+nnD59Ol9++SUADRo0AMDFxQX45Zm7X3zxhWPsc889x+7du8n6ageuOpRczuHnz9ZQkpd1zXxFGSlk73yTkvxs7CVF5OxfT8nP5/C4MwyzSSfoDu+bPp+yeHt78/333zu+t9vt9OrVi7CwMJKTk6lTpw49e/Ys17FENaWEcIL9+/ergIAApWma0jRNhYSEqLFjxypvb2/HmNjYWGUymRSgQkNDla+vr4qMjFRKKRUWFqZ0XVeAMplMasSIEY79hg0b5tg2depUpZRSc+fOVR6engpQaJpy8bKqBhPfVo1jEhSarizdRqvGMQmqcUyCuiM6Tmnu/38sKFxclWfr7qpxTIJq+fdElZlnK9f5KKX+cE5KKQWopKQkpZRS8fHxytXV1bHPwIEDldlsVnl5eUoppb766iulaZpaunRpBb77oiqRO9JEjfbEO4fYeSL9urf+lslup/CnQ3Q3fc+9995LYGAggYGBtG/fXtZdxS2T0hU12jdncxj61ucUFF+96X3Nrjpp7z7LpZ+Ooes6derUIS8vj08++YT77ruvEtKK2kBKV9R4vzzs5sQtPXsh2DWLe++917G+3KZNG44ePXrNX4gJUR7y/0iixhvZuQmz+gbj4epyw4sWNA08XF0cD7sJDQ1l8ODBmEwmXFxcOH78OAMGDKCw8I93qQlRHjLTFbXG0dQclu05xe7vMtAA2zWep9v9Ln8mdGte6iE3GRkZNG3alPnz59O2bVseeeQRiouLWb16NX/729+cfh6iepPSFbVOVn4hm75OJflCHrm2YnzMrgTd4c2gjmV/ckRmZiZWqxVN07Db7YwePZp3332Xrl27kpCQgLe39zX3E+L3pHSFuEWHDh2iX79+5OTksGzZMsaMGWN0JFENyJquELeoU6dOnD9/nnHjxvH4448TGhp63dt9hQApXSH+FF3XWbJkCd9++y3Z2dnUr1+fV1991ehYogqT0hWiAtx111389NNPzJo1i2effZagoCBSUlKMjiWqICldISrQiy++yOnTp3FxcaFZs2bMmjXL6EiiipFfpAlRSZYsWcLMmTMJCAhg+/bttG7d2uhIogqQma4QlWTKlClcuHCBO+64g5CQEMaPH4/dXv674kTNJDNdIZxg9erVjBs3Dm9vb7Zu3co999xjdCRhEJnpCuEEkZGRZGRkEBISQpcuXRg2bBglJSVGxxIGkNIVwkm8vLxISkpiy5YtJCQk4Ofnx8cff2x0LOFkUrpCOFn//v3JysrigQceoHfv3vTt2/eWPvpHVE9SukIYwM3NjQ8++IDdu3dz8OBBrFYrGzZsMDqWcAIpXSEMdP/995ORkcHgwYMZOnQoXbt2lQ+mrOGkdIUwmK7rrFy5kkOHDvHDDz/g7+/P8uXLjY4lKomUrhBVRMeOHUlNTWXixImMHz+eDh06kJaWZnQsUcGkdIWoQnRdZ/HixSQnJ5Obm0tgYCAvv/yy0bFEBZKbI4SowubOnUtsbCzNmjXjo48+omnTpkZHEn+SzHSFqMJeeOEFzpw5g9lspnnz5jz77LNGRxJ/ksx0hagmXn/9daZPn07dunVJTEwkJCTE6EjiFshMV4hq4qmnnuLixYsEBgbSvn17nnjiCXmATjUkpStENWKxWDhw4ADvvPMO7777LnXr1mXfvn1GxxI3QUpXiGpoxIgRZGZmEhoaSteuXRk8eLA8QKeakDVdIaq5xMREhg4dCsCxY8do3LixwYnE9UjpClEDlJSUMGzYMN577z1cXV1LbVNKsXr1agBGjRplRDzxG7K8IEQNYDKZ2LhxIyaT6Q/bsrOzsdvtbNq0ieDgYHbs2AH8UsbC+WSmK0QtsnXrVt5//31WrlyJpmnk5ORgsViMjlWryExXiFrg1+f1njp1ijp16vDdd9/x+uuv0717d4YOHcqpU6cMTlh7SOkKUUP99n9izWYzR44cYfny5QwePJiJEyeSk5PD+++/T926dVm7dq2BSWuXPy4ACSFqBE3TAFixYgU7duygoKCAhQsXYjKZSE1N5e9//zsAw4cPZ+XKleTl5eHt7W1k5FpBSleIGkgpxYYNG1i2bBlt27Zl8uTJtG7dGqvVSkREBJMnT3aMTU5O5syZM1K4TiLLC0LUQHa7nZMnT3L48GGuXLlCixYtsFqtfP/992RnZzNx4kTH2EWLFjF69GjHfqJySekKUQO5uLjwwgsvcOHCBVq2bEnPnj1Zs2YN58+fJzw83DHuo48+wmazMWTIEOCX5/mKyiWXjAlRS6SlpeHj40O/fv14/PHH8fHx4a233mLAgAFERUVht9vRNM2xFiwqh5SuELXMtm3bePXVV/Hz8yM6OpqHHnrIsU0pRXJyMsHBwQYmrNmkdIWopfLz8/Hy8ir1WkFBAXXq1GHgwIGsXbsWNzc3g9LVXLKAI0Qt9fvCBfDw8CAxMZGkpCSsVisJCQkGJKvZpHSFEKX07t2brKwsHn74Yfr378+DDz7IlStXjI5VY0jpCiH+wGQysW7dOvbt28eRI0ewWq28++67RseqEaR0hRBl6tKlC+np6YwaNYrIyEg6d+5Mdna20bGqNSldIcR16brOm2++ydGjRzl//jwBAQEsXbrU6FjVlpSuEKJc2rRpw5kzZ3j66aeZOnUqbdq0ITU11ehY1Y6UrhDipixYsIAffviB4uJimjRpQmxsrNGRqhW5TlcIccsWLVrE888/T2BgINu3b+euu+4yOlKVJzNdIcQtmzlzJufOncNisdCqVSumTZsmD825AZnpCiEqxIoVK3jqqae47bbb2LZtGx07djQ6UpUkM10hRIWIjo7m4sWLtGjRgk6dOjF69GiZ9V6DlK4QosL4+Pjw6aefsmHDBjZu3Iifnx979uwxOlaVIqUrhKhwgwYNIisri3vvvZcHHniAv/71rxQVFRkdq0qQ0hVCVAqz2UxCQgI7d+5kz5493H777Xz44YdGxzKclK4QolL16NGDzMxMBgwYwMCBA3nggQfIz883OpZhpHSFEJXOZDKxZs0aDh48yH/+8x/8/f15++23jY5lCCldIYTThIWFceHCBcaOHcuYMWMICwsjMzPT6FhOJaUrhHAqXdd5/fXXOX78OBcvXqR+/fq89tprRsdyGildIYQhgoODSUlJ4ZlnnmHGjBm0atWKM2fOGB2r0knpCiEMNW/ePH788UeUUjRr1ox//OMfRkeqVHIbsBCiyli8eDHPPvssDRo0YPv27TXyU4llpiuEqDKmT5/OhQsX8Pf3p02bNkyaNKnG3UosM10hRJW0cuVKxo8fj6+vLwkJCYSFhRkdqULITFcIUSVFRUWRmZlJq1atuOeeexg5ciQlJSXk5OQQFRVVbT+h2GR0ACGEKIuXlxe7d+9m8+bNPPbYY/j7+xMaGsru3bsJCAhgwYIF19wvM7+QTV+lkpyWS66tBB+ziaAAHx4NbYjVy93JZ1GaLC8IIaqFoqIiunXrxoEDB4Bfnu3w7bff0rRpU8eYb87m8MaeU3xyMgOAwpL/rgebTToK6HaXPxPub067QIsz4ztI6QohqgWbzUaTJk1IT093vNauXTuOHDkCwLufn2Z+YjK2kqtcr9U0DcwmF2b1DWJk5yaVG/oaZE1XCFFpoqOj8fHxqZBjFRUV0b17dzp06EDdunXRNI1vvvmGsWPH8s6B08xPPEFB8fULF0ApKCi+yvzEE7z7+ekKyXYzZE1XCFHlaZpGUlISa9eudbymlOL48eMsWP4e87efwFZc9qVldtsVLrw9lZKcNFB2MLnh2/lR5jOSkIYWQhpaKiyrxWIhJyenzO0y0xVCVEuaptG2bVu87n6k1Nrt79lLirBfLcLF63bqDVtA4DNb8Ln7b1zau4affzzKsj2nnJhaSlcIUUEOHjxI/fr10XUdXdcJCQkptX3v3r1omobNZnO8ZrFYGDVqFAC7du3CYrGgaRq6rtOoUSMAfH19AejZsyeapjFlyhQAZs+ejYeHB29FhpHy6qNcTt7rOG7Kwv6kb/gHKYsGcvaff0N39yRgxMuYG7VG103cdt9IcHHlysnP2f1dBln5heU+n1+XTDp16oSu67i6ujJnzhwAwsPDuXTp0nXfJyldIcSf9uuVBQEBAaSlpZGdnc2TTz55U8f49VGPxcXFZGdnExMTA+AosaSkJJRSLFmyhLVr1zJv3jwGTZpN85gteAZ3JfPDV7Db/nvtru3MMeoNX0CDye+hm9xK5804DVeLMTcJQQM2fZ16U+eTl5dHq1atsNlsDBo0iNjYWOx2O/v27XP8JVEWKV0hxJ+2atUqCgsL2b9/P3Xr1sVisTBhwoSbOobJZCI1NZXDhw/fcP958+YRHh6ONbQ3xZjw6zMZNJ38YzsdY+oEdcXcIAiTZ+lf5NmLbKSvicFkbYjnnWHYSuwkX8i7qfMxmUysXr0aNzc3li5dit1u5/jx4+U6TyldIcSfduLECTw8PDCbzbd8jM2bN6OUonPnzpjNZqKiosocm5GRwd69e1kytCMpL/cj5eV+YC+h5OcLjjGu1oZ/2M9uL+H8iidB07lj1GuO1+Oiu6NpGpqmMWHChBuej4eHh+NrPz8/R6bykKsXhBB/WnBwMAUFBdhstjKLymq1ApCZmUnDhr8UYkFBgWN7SEgIycnJACxbtoyJEycycuRIevTocc1jtWvXjtbRr7DlyPlrh9K0Ut/a7XYuvDUee2EB9ce9he7235zjV+zm/w1p7/h++fLlNzyfsmi/+7m/JzNdIcSfNnr0aNzd3YmIiODixYvk5OQQFxdXakxwcDC6rjNjxgyKioqIiooq9bHs06dP58svvwSgQYMGALi4uAC/fNrEF1984Rj73HPPsXv3brK+2oGrDiWXc/j5szWU5GWVmfHCvyZyNf9n6j8eV2rJwWzSCbrD+6bPpyze3t7XH6CEEKIC7N+/XwUEBChN05SmaSokJESNHTtWeXt7O8bExsYqk8mkABUaGqp8fX1VZGSkUkqpsLAwpeu6ApTJZFIjRoxw7Dds2DDHtqlTpyqllJo7d67y8PRUgELTlIuXVTWY+LZqHJOg0HRl6TZaNY5JUI1jElS9ka/8Mu53f7w69FUt/56oMvNs5TofpdQfzkkppQCVlJSklFIqPj7+uu+T3AYshKjWnnjnEDtPpN/wTrRr0TTo1aoeb47sVPHByiDLC0KIam1it+aYTS63tK/Z5MKEbs0rONH1SekKIaq1doEWZvUNwsP15urMw1VnVt+gCr0FuDzk6gUhRLX369PCqsNTxmRNVwhRYxxNzWHZnlPs/i4DDbBd43m63e/yZ0K35k6f4f5KSlcIUeNk5Rey6etUki/kkWsrxsfsStAd3gzqKJ8cIYQQtYr8Ik0IIZxISlcIIZxISlcIIZxISlcIIZxISlcIIZxISlcIIZxISlcIIZxISlcIIZxISlcIIZxISlcIIZxISlcIIZxISlcIIZxISlcIIZxISlcIIZxISlcIIZzo/wCsSnA3XwB7ugAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "\n",
    "def draw(G):\n",
    "    infra = nx.DiGraph()\n",
    " #   for cl in range(len(G)):\n",
    " #       i = list(G.keys())[cl]\n",
    " #       infra.add_node(i)\n",
    "    for cl in range(len(G)):\n",
    "        i = list(G.keys())[cl]\n",
    "        for link in range(len(G[i])):\n",
    "            infra.add_edges_from([(i, G[i][link])], weight=link_latency[i][G[i][link]])\n",
    "    edge_labels=dict([((u,v,),d['weight'])\n",
    "                 for u,v,d in infra.edges(data=True)])\n",
    "\n",
    "\n",
    "    pos = nx.spring_layout(infra)\n",
    "    nx.draw_networkx_edge_labels(infra,pos,edge_labels=edge_labels)\n",
    "    nx.draw_networkx_labels(infra, pos)\n",
    "    #plt.figure(figsize=(8,8))\n",
    "    \n",
    "    nx.draw(infra, pos=pos, with_labels=True)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The number of running pods of a microservice on each cluster\n",
    "import os\n",
    "def runningPods(cluster, app_name): \n",
    "    output = os.popen('sudo kubectl top pod --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    numPods = 0\n",
    "    which_app = len(app_name)\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if len(items[0]) > 8 and items[0][:which_app] == app_name:\n",
    "            numPods += 1\n",
    "    return numPods\n",
    "runningPods(\"cluster1-cntx\",\"firewall\"+'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The utilised CPU of a microservice running on a cluster\n",
    "import os\n",
    "def getchar(string, n):\n",
    "    return str(string)[n - 1]\n",
    "def cpuUtilised(cluster, app_name):\n",
    "    output = os.popen('kubectl top pod --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    which_app = len(app_name)\n",
    "    cpu = ''\n",
    "    cpu_u=0\n",
    "    limits=0\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if items[0][:which_app] == app_name:\n",
    "            if getchar(items[0], which_app) == 's':\n",
    "                cpu = items[1]\n",
    "                cpu = cpu[:-1]\n",
    "                cpu = int(cpu)\n",
    "                cpu_u=cpu_u + cpu\n",
    "            if getchar(items[0], which_app) == 'm':\n",
    "                cpu = items[1]\n",
    "                cpu = cpu[:-1]\n",
    "                cpu = int(cpu)\n",
    "                cpu_u=cpu_u + cpu\n",
    "            if getchar(items[0], which_app) == 'l':\n",
    "                cpu = items[1]\n",
    "                cpu = cpu[:-1]\n",
    "                cpu = int(cpu)\n",
    "                cpu_u=cpu_u + cpu\n",
    "\n",
    "        \n",
    "                \n",
    "#    print(limits - cpu_u)\n",
    "    return cpu_u\n",
    "\n",
    "\n",
    "cpuUtilised(\"cluster1-cntx\",\"firewall\"+'m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The available CPU of a microservice running on a cluster\n",
    "import os\n",
    "def getchar(string, n):\n",
    "    return str(string)[n - 1]\n",
    "def cpuAvail(cluster, app_name):\n",
    "    output = os.popen('kubectl top pod --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    which_app = len(app_name)\n",
    "    cpu = ''\n",
    "    cpu_u=0\n",
    "    limits=0\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if items[0][:which_app] == app_name:\n",
    "            if getchar(items[0], which_app) == 's':\n",
    "                limits = 600\n",
    "                cpu = items[1]\n",
    "                cpu = cpu[:-1]\n",
    "                cpu = int(cpu)\n",
    "                cpu_u=cpu_u + cpu\n",
    "            if getchar(items[0], which_app) == 'm':\n",
    "                limits = 5*600\n",
    "                cpu = items[1]\n",
    "                cpu = cpu[:-1]\n",
    "                cpu = int(cpu)\n",
    "                cpu_u=cpu_u + cpu\n",
    "            if getchar(items[0], which_app) == 'l':\n",
    "                limits = 10*600\n",
    "                cpu = items[1]\n",
    "                cpu = cpu[:-1]\n",
    "                cpu = int(cpu)\n",
    "                cpu_u=cpu_u + cpu\n",
    "\n",
    "        \n",
    "                \n",
    "#    print(limits - cpu_u)\n",
    "    return limits - cpu_u\n",
    "\n",
    "\n",
    "cpuAvail(\"cluster1-cntx\",\"firewall\"+'s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Which microservice configuration is running: small, medium, or large\n",
    "def getchar(string, n):\n",
    "    return str(string)[n - 1]\n",
    "def whichConf(cluster, app_name):\n",
    "    size = []\n",
    "    output = os.popen('sudo kubectl get services --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    which_app = len(app_name)\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if items[0][:which_app] == app_name:\n",
    "            size.append(getchar(items[0], which_app+1))\n",
    "    #        print(size)\n",
    "    return size\n",
    "whichConf(\"cluster1-cntx\",\"firewall\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Monitor and delete function</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"<h1>Monitor and delete function</h1>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread is starting\n",
      "firewalls timed out\n",
      "thread is starting\n",
      "encrypts timed out\n"
     ]
    }
   ],
   "source": [
    "#This function is terminate services once idle for a time \n",
    "import threading\n",
    "import time\n",
    "import os\n",
    "\n",
    "def deletePod(app_name, timer, cluster):\n",
    "    print(\"thread is starting\")\n",
    "    cpu = 0\n",
    "    timeout = time.time() + timer\n",
    "    while cpu == 0:\n",
    "        cpu= cpuUtilised(cluster, app_name)\n",
    "        if time.time() > timeout:\n",
    "            try:\n",
    "                os.system(\"sudo kubectl delete service \"+ app_name +\" --context=\" + cluster)\n",
    "                os.system(\"sudo kubectl delete deploy \"+ app_name +\" --context=\" + cluster)\n",
    "                print(app_name+ \" timed out\")\n",
    "                break\n",
    "            except:\n",
    "                print(\"Service not found\")\n",
    "                break\n",
    "        \n",
    "def monitorUsage(cluster, timer):\n",
    "    for service in range(len(bf)):\n",
    "        threads = list()\n",
    "        ser = list(bf.keys())[service]\n",
    "        s = whichConf(cluster,ser)\n",
    "        if s != []:\n",
    "            for size in range(len(s)):\n",
    "                app_name=ser+s[size]\n",
    "                x =threading.Thread(target=deletePod, args=(app_name, timer, cluster,))\n",
    "                x.daemon = True\n",
    "                threads.append(x)\n",
    "                x.start()\n",
    "            for x in threads:\n",
    "                x.join()\n",
    "\n",
    "        \n",
    "monitorUsage(\"cluster1-cntx\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This function orders the running microservies on a cluster increasingly according to proccessing delay\n",
    "def orderService(cluster, app_name):\n",
    "    delay = []\n",
    "    size = whichConf(cluster, app_name)\n",
    "    for s in range(len(size)):\n",
    "        delay.append(bf[app_name][app_name+size[s]])\n",
    "    sorted_delay = [x for _,x in sorted(zip(delay,size))]\n",
    "    return sorted_delay\n",
    " #   print(delay)\n",
    "                \n",
    "    \n",
    "orderService(\"cluster1-cntx\",\"firewall\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "def getIP(cluster, app_name):\n",
    "    output = os.popen('kubectl get service -o wide --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    serviceIP = ''\n",
    "    port=''\n",
    "    which_app = len(app_name)\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if items[0][:which_app] == app_name:\n",
    "            serviceIP=items[2]+\":\"+items[4][:4]\n",
    "    return serviceIP\n",
    "getIP(\"cluster1-cntx\",\"firewall\"+'m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cluster1-cntx', 'cluster3-cntx']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This function orders the available links from source cluster increasingly according to latency\n",
    "def orderlink(cluster):\n",
    "    delay = []\n",
    "    cnx = []\n",
    "    for key in range(len(list(link_latency[\"cluster1-cntx\"].keys()))):\n",
    "        delay.append(link_latency[\"cluster1-cntx\"][list(link_latency[\"cluster1-cntx\"].keys())[key]])\n",
    "        cnx.append(list(link_latency[\"cluster1-cntx\"].keys())[key])\n",
    "    sorted_delay = [x for _,x in sorted(zip(delay,cnx))]\n",
    "    return sorted_delay\n",
    " #   print(delay)\n",
    "                \n",
    "    \n",
    "orderlink(\"cluster1-cntx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-198"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Available CPU on a cluster in millicores\n",
    "def clusterCPU(cluster):\n",
    "    cpu=0\n",
    "    cpu_cl=0\n",
    "    output = os.popen('sudo kubectl top nodes --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if items[0] != \"NAME\":\n",
    "            cpu = items[1]\n",
    "            cpu = cpu[:-1]\n",
    "            cpu = int(cpu)\n",
    "            cpu_cl = cpu_cl + cpu\n",
    "    #        print(size)\n",
    "    return 2000 - cpu_cl\n",
    "\n",
    "clusterCPU('cluster1-cntx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.333333333333336"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Available CPU percentage on a cluster in\n",
    "def clusterCPUPerc(cluster):\n",
    "    cpu=0\n",
    "    cpu_cl=0\n",
    "    output = os.popen('sudo kubectl top nodes --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if items[0] != \"NAME\":\n",
    "            cpu = items[2]\n",
    "            cpu = cpu[:-1]\n",
    "            cpu = int(cpu)\n",
    "            cpu_cl = cpu_cl + cpu\n",
    "    #        print(size)\n",
    "    return cpu_cl/3\n",
    "\n",
    "clusterCPUPerc('cluster1-cntx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1572"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Available memory on a cluster in MB\n",
    "def clusterMem(cluster):\n",
    "    mem=0\n",
    "    mem_cl=0\n",
    "    nodes=0\n",
    "    output = os.popen('sudo kubectl top nodes --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if items[0] != \"NAME\":\n",
    "            mem = items[3]\n",
    "            mem = mem[:len(mem)-2]\n",
    "            nodes=nodes+1\n",
    "            mem = int(mem)\n",
    "            mem_cl = mem_cl + mem\n",
    "    #print(nodes)\n",
    "    #print(mem_cl)\n",
    "    return nodes*1915 - mem_cl\n",
    "\n",
    "clusterMem('cluster2-cntx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Place and Assign new mircroservice to requests</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"<h1>Place and Assign new mircroservice to requests</h1>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place(i, q, s):\n",
    "#    i = 'cluster2-cntx'\n",
    "    if s == 's':\n",
    "        os.system('sudo kubectl apply -f ~/SOCKS-deployement/'+q+'-S.yaml --context=' + i)\n",
    "    elif s == 'm':\n",
    "        os.system('sudo kubectl apply -f ~/SOCKS-deployement/'+q+'-M.yaml --context=' + i)\n",
    "    elif s == 'l':\n",
    "        os.system('sudo kubectl apply -f ~/SOCKS-deployement/'+q+'-L.yaml --context=' + i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignService(i, q, usecase_s):\n",
    "#    req = 1\n",
    "#    cl = 1\n",
    "    proxy_conf='' \n",
    "    size=[]\n",
    "    avail=0\n",
    "    cpu_q= usecase_s[u][q]\n",
    "    r = runningPods(i, q)\n",
    "    if r >= 1: #there's a function already running on this cluster \n",
    "        size = orderService(i,q) #which function size is running? order by delay\n",
    "        for s in range(len(size)): \n",
    "            avail = cpuAvail(i, q+size[s]) #the available CPU depends on the service configuration\n",
    "            if avail > cpu_q: #if the available resources > profiled resources requested \n",
    "                proxy_conf=getIP(i,q+size[s]) #then get IP to assign the service to proxy\n",
    "                break\n",
    "    elif r ==0 : #no service running \n",
    "        proxy_conf=''          \n",
    "    #print(proxy_conf)\n",
    "    return proxy_conf\n",
    "\n",
    "def newService(i,q, usecase_s):\n",
    "    proxy_conf=''\n",
    "    cpu_q= usecase_s[u][q]\n",
    "    r = runningPods(i, q)\n",
    "    if 600 > cpu_q and runningPods(i, q+'s') == 0 and 600 < clusterCPU(i): #deploy new small service\n",
    "        place(i,q,'s')\n",
    "        proxy_conf=getIP(i,q+'s')       \n",
    "    elif 5*600 > cpu_q and runningPods(i, q+'m')==0 and 5*600 < clusterCPU(i): #deploy new medium service\n",
    "        proxy_conf=getIP(i,q+'m')\n",
    "        proxy_conf=getIP(i,q+'m')\n",
    "    elif 10*600 > cpu_q and runningPods(i, q+'l')==0 and 10*600 < clusterCPU(i): #deploy new large service\n",
    "        proxy_conf=getIP(i,q+'l')\n",
    "        proxy_conf=getIP(i,q+'l')\n",
    "  #  elif proxy_conf=='':\n",
    "  #      print(\"placement failed\")\n",
    "        \n",
    "    \n",
    "    #print(proxy_conf)\n",
    "    return proxy_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cluster1-cntx', 'cluster2-cntx']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Returns the lists of clusters on which a microservice type is running\n",
    "def checkdeploy(app_name):\n",
    "    cl = 0\n",
    "    p=0\n",
    "    cluster=[]\n",
    "    while p == 0:\n",
    "        for cl in range(len(G)):\n",
    "            i = list(G.keys())[cl]\n",
    "            output = os.popen('sudo kubectl get services --context=' +i).read()\n",
    "            lines = output.split(\"\\n\")\n",
    "            which_app = len(app_name)\n",
    "            for line in lines[:-1]:\n",
    "                items = line.split()\n",
    "                if items[0][:which_app] == app_name:\n",
    "                    cluster.append(i)\n",
    "                    p=1\n",
    "                    \n",
    "    return cluster\n",
    "checkdeploy(\"proxy\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proxyConfig(IP, proxy):\n",
    "    newChain = []\n",
    "    for ip in range(len(IP)):\n",
    "        newChain.append('\"-c\",'+'\"socks6://'+IP[ip]+'\",')\n",
    "    newChain = ''.join(newChain)\n",
    "    newChain = newChain[:-1]\n",
    "    print(newChain)\n",
    "    os.system(\"sudo kubectl patch deployment \"+ proxy +\" --namespace default --type='json' -p='[{'op': 'replace', 'path': '/spec/template/spec/containers/0/args', 'value': [\"+newChain+\"]}]'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-efdbc8cfce0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_ser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"proxy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-65-efdbc8cfce0b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(proxy, G_req)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#go over functions to deploy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm_ser\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#The first function can be deployed on any cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0massignService\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecase\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#there is atleast one good candidate service running on i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                     \u001b[0mIPs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massignService\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mm_cl\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;31m#to check connection with next deployment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-57935d25dcfc>\u001b[0m in \u001b[0;36massignService\u001b[0;34m(i, q, usecase_s)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mavail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcpu_q\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0musecase_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunningPods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#there's a function already running on this cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morderService\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#which function size is running? order by delay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-0e6d68ab18e6>\u001b[0m in \u001b[0;36mrunningPods\u001b[0;34m(cluster, app_name)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrunningPods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapp_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sudo kubectl top pod --context='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnumPods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main(proxy, G_req):\n",
    "    IPs = []\n",
    "    m_cl= ''\n",
    "    m_ser=[]\n",
    "    proxy_idx=proxy\n",
    "    startingCluster = checkdeploy(proxy_idx)\n",
    "    OG = orderlink(startingCluster) #try the fastest link first\n",
    "    for cl in range(len(OG)): #go over clusters \n",
    "        i = list(G.keys())[cl]\n",
    "        for req in range(len(G_req)):\n",
    "            q = list(G_req.keys())[req] #go over functions to deploy\n",
    "            if req == 0 and q not in m_ser: #The first function can be deployed on any cluster\n",
    "                if assignService(i,q, usecase) != \"\": #there is atleast one good candidate service running on i \n",
    "                    IPs.append(assignService(i,q, usecase))\n",
    "                    m_cl= i #to check connection with next deployment\n",
    "                    m_ser.append(q)\n",
    "                    continue                \n",
    "            elif m_cl in G[i] and q not in m_ser: #connection with previous bf and not already deployed\n",
    "                if assignService(i,q, usecase) != \"\": #can be deployed\n",
    "                    IPs.append(assignService(i,q, usecase))\n",
    "                    m_cl= i\n",
    "                    m_ser.append(q)\n",
    "                    continue\n",
    "        if len(m_ser) < len(G_req): #not all deployed yet we try a different cluster      \n",
    "            continue \n",
    "        else:\n",
    "            break\n",
    "    if len(m_ser) < len(G_req): #not all functions could be deployed \n",
    "        for cl in range(len(OG)): #go over clusters \n",
    "            i = list(G.keys())[cl]\n",
    "            for req in range(len(G_req)):\n",
    "                q = list(G_req.keys())[req] #go over functions to deploy\n",
    "                if req == 0 and q not in m_ser:\n",
    "                    if newService(i,q, usecase) != '':\n",
    "                        IPs.append(newService(i,q, usecase))\n",
    "                        m_cl= i\n",
    "                        m_ser.append(q)\n",
    "                        continue\n",
    "                elif m_cl in G[i] and q not in m_ser: #connection with previous bf and not already deployed\n",
    "                        if newService(i,q, usecase) != '':\n",
    "                            IPs.append(newService(i,q, usecase))\n",
    "                            m_cl= i\n",
    "                            m_ser.append(q)\n",
    "                            continue  \n",
    "    proxyConfig(IPs, proxy)\n",
    "    print(IPs)\n",
    "    print(m_ser)\n",
    "    \n",
    "main(\"proxy\", G_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Deploy and monitor microservices</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"<h1>Deploy and monitor microservices</h1>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = list()\n",
    "x =ThreadWithResult(target=main)\n",
    "x.daemon = True\n",
    "x.start()\n",
    "threads.append(x)\n",
    "for cl in range(len(G)): #go over clusters \n",
    "        i = list(G.keys())[cl]\n",
    "        x = ThreadWithResult(target=monitorUsage, args=(i,10, ))\n",
    "        x.daemon = True\n",
    "        threads.append(x)\n",
    "        x.start()\n",
    "for x in threads:\n",
    "    x.join()\n",
    "    print(x.result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
